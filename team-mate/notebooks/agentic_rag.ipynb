{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../weaviate_utils')\n",
    "\n",
    "\n",
    "def load_env():\n",
    "    _ = load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "def get_openai_api_key():\n",
    "    load_env()\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    return openai_api_key\n",
    "\n",
    "def get_langchain_api_key():\n",
    "    load_env()\n",
    "    langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "    return langchain_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = get_openai_api_key()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE1 - LangGraph - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = get_langchain_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mubarek/anaconda3/envs/team-mate/lib/python3.11/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate is ready\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=\"http://localhost:8080\",\n",
    "    timeout_config=(5, 300),\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "if client.is_ready():\n",
    "    print(\"Weaviate is ready\")\n",
    "else:\n",
    "    print(\"Weaviate is not ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate_interface import WeaviateInterface\n",
    "\n",
    "weaviate_url = \"http://localhost:8080\"\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "schema_file = '../weaviate_utils/schema.json'\n",
    "\n",
    "weaviate_interface = WeaviateInterface(weaviate_url, openai_key, schema_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8080/v1/schema \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate schema initialization complete\n"
     ]
    }
   ],
   "source": [
    "async def initialize_weaviate():\n",
    "    await weaviate_interface.async_init()\n",
    "    print(\"Weaviate schema initialization complete\")\n",
    "\n",
    "await initialize_weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader, CSVLoader\n",
    "\n",
    "def load_documents(file_path: str, file_type: str = None):\n",
    "    if file_type == 'csv' and not file_path.endswith('.csv'):\n",
    "        raise ValueError(f\"Expected a CSV file, but got {file_path}\")\n",
    "    if file_path.endswith('.csv'):\n",
    "        loader = CSVLoader(file_path)\n",
    "    else:\n",
    "        if file_type is None:\n",
    "            loader = UnstructuredFileLoader(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type for {file_path}\")\n",
    "    return loader.load()\n",
    "\n",
    "# Example file paths\n",
    "file_paths = [\"../files/Tenacious Talent - GenAI Upskilling.pdf\"]\n",
    "all_documents = []\n",
    "for file_path in file_paths:\n",
    "    documents = load_documents(file_path)\n",
    "    all_documents.extend(documents)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1024, chunk_overlap=50)\n",
    "chunked_documents = text_splitter.split_documents(all_documents)\n",
    "print(f\"Number of chunks: {len(chunked_documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks: {len(chunked_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8080/v1/batch/objects \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added to Weaviate\n"
     ]
    }
   ],
   "source": [
    "async def add_documents_to_weaviate(client, documents, class_name=\"DocumentChunk\", batch_size=70):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        objects = [{\"text\": doc.page_content, \"doc_name\": \"Example Document\"} for doc in batch]\n",
    "        await client.batch_create_objects(objects, class_name)\n",
    "    print(\"Documents added to Weaviate\")\n",
    "\n",
    "await add_documents_to_weaviate(weaviate_interface.client, chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vectorstore similarity search for retrieval\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "vectorstore = Weaviate(client, \"DocumentChunk\", \"text\", attributes=[\"doc_name\"])\n",
    "\n",
    "RAG_PROMPT = \"\"\"\n",
    "Use the following context to answer the user's query. If you cannot answer the question, please respond with 'I don't know'. and Please highly consider the context when answering the question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
    "openai_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "retrieval_augmented_generation_chain = (\n",
    "    {\"context\": itemgetter(\"question\"), \"retrieved_docs\": lambda d: vectorstore.similarity_search(d[\"question\"], k=5), \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | openai_chat_model, \"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import asyncio\n",
    "from tenacity import retry, wait_fixed, stop_after_attempt, wait_exponential\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Enhanced error handling for similarity search\n",
    "# Error handling for similarity search\n",
    "@retry(wait=wait_exponential(min=1, max=10), stop=stop_after_attempt(5))\n",
    "async def fetch_similar_docs(question: str):\n",
    "    try:\n",
    "        result = vectorstore.similarity_search(question, k=5)\n",
    "        return result\n",
    "    except ValueError as e:\n",
    "        error_message = str(e)\n",
    "        if \"rate_limit_exceeded\" in error_message:\n",
    "            logging.error(\"Weaviate rate limit exceeded. Please try again later.\")\n",
    "            raise\n",
    "        else:\n",
    "            logging.error(f\"Error during similarity search: {error_message}\")\n",
    "            raise\n",
    "\n",
    "# Error handling for answer generation\n",
    "@retry(wait=wait_fixed(30), stop=stop_after_attempt(10))\n",
    "async def generate_answer(question: str, retrieved_docs: list):\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    input_data = {\n",
    "        \"question\": question,\n",
    "        \"context\": context\n",
    "    }\n",
    "    try:\n",
    "        result = await retrieval_augmented_generation_chain.ainvoke(input_data)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during answer generation: {e}\")\n",
    "        raise\n",
    "\n",
    "async def example_usage(question: str):\n",
    "    try:\n",
    "        logging.info(\"Retrieving documents...\")\n",
    "        retrieved_docs = await fetch_similar_docs(question)\n",
    "        if not retrieved_docs or all(doc.page_content.strip() == \"\" for doc in retrieved_docs):\n",
    "            logging.info(\"No sufficient context found in Weaviate, using DuckDuckGo search.\")\n",
    "            return None  # Indicate that no sufficient context was found\n",
    "        logging.info(\"Retrieved documents:\")\n",
    "        for doc in retrieved_docs:\n",
    "            logging.info(f\"Document name: {doc.metadata['doc_name']}, Content snippet: {doc.page_content[:200]}\")\n",
    "        logging.info(\"Generating answer...\")\n",
    "        result = await generate_answer(question, retrieved_docs)\n",
    "        logging.info(f\"Generated response: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred:\", exc_info=True)\n",
    "        return \"An unexpected error occurred.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_question(question: str):\n",
    "    answer = await example_usage(question)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Retrieving documents...\n",
      "INFO:root:Retrieved documents:\n",
      "INFO:root:Document name: Example Document, Content snippet: Tenacious Talent - GenAI\n",
      "\n",
      "UpSkilling\n",
      "\n",
      "GEN-AI Challenge\n",
      "\n",
      "TEAM-MATE:\n",
      "\n",
      "Personalized Agent for Optimising Trainee Time and Focus\n",
      "\n",
      "Business objective\n",
      "\n",
      "TeamMate (not a real company, this is a scenario) is a\n",
      "INFO:root:Document name: Example Document, Content snippet: Tenacious Talent - GenAI\n",
      "\n",
      "UpSkilling\n",
      "\n",
      "GEN-AI Challenge\n",
      "\n",
      "TEAM-MATE:\n",
      "\n",
      "Personalized Agent for Optimising Trainee Time and Focus\n",
      "\n",
      "Business objective\n",
      "\n",
      "TeamMate (not a real company, this is a scenario) is a\n",
      "INFO:root:Document name: Example Document, Content snippet: Tenacious Talent - GenAI\n",
      "\n",
      "UpSkilling\n",
      "\n",
      "GEN-AI Challenge\n",
      "\n",
      "TEAM-MATE:\n",
      "\n",
      "Personalized Agent for Optimising Trainee Time and Focus\n",
      "\n",
      "Business objective\n",
      "\n",
      "TeamMate (not a real company, this is a scenario) is a\n",
      "INFO:root:Document name: Example Document, Content snippet: Tenacious Talent - GenAI\n",
      "\n",
      "UpSkilling\n",
      "\n",
      "GEN-AI Challenge\n",
      "\n",
      "TEAM-MATE:\n",
      "\n",
      "Personalized Agent for Optimising Trainee Time and Focus\n",
      "\n",
      "Business objective\n",
      "\n",
      "TeamMate (not a real company, this is a scenario) is a\n",
      "INFO:root:Document name: Example Document, Content snippet: Tenacious Talent - GenAI\n",
      "\n",
      "UpSkilling\n",
      "\n",
      "GEN-AI Challenge\n",
      "\n",
      "TEAM-MATE:\n",
      "\n",
      "Personalized Agent for Optimising Trainee Time and Focus\n",
      "\n",
      "Business objective\n",
      "\n",
      "TeamMate (not a real company, this is a scenario) is a\n",
      "INFO:root:Generating answer...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Generated response: {'response': AIMessage(content='The Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition or program focused on upskilling individuals in artificial intelligence (AI) through various challenges and activities. It likely involves developing AI solutions, enhancing skills in AI technologies, and promoting innovation in the field.', response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 82, 'total_tokens': 139}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cf7d0155-24a4-4efa-82c9-ca9ac4b18629-0', usage_metadata={'input_tokens': 82, 'output_tokens': 57, 'total_tokens': 139}), 'context': 'What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?', 'question': 'What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': AIMessage(content='The Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition or program focused on upskilling individuals in artificial intelligence (AI) through various challenges and activities. It likely involves developing AI solutions, enhancing skills in AI technologies, and promoting innovation in the field.', response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 82, 'total_tokens': 139}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cf7d0155-24a4-4efa-82c9-ca9ac4b18629-0', usage_metadata={'input_tokens': 82, 'output_tokens': 57, 'total_tokens': 139}), 'context': 'What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?', 'question': 'What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?'}\n"
     ]
    }
   ],
   "source": [
    "question1 = \"What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?\"\n",
    "answer1 = await ask_question(question1)\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, FunctionMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langgraph.graph import StateGraph, END\n",
    "import operator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "tool_belt = [DuckDuckGoSearchRun()]\n",
    "tool_executor = ToolExecutor(tool_belt)\n",
    "model = ChatOpenAI(temperature=0)\n",
    "functions = [convert_to_openai_function(t) for t in tool_belt]\n",
    "model = model.bind_functions(functions)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    logging.info(f\"Calling model with messages: {messages}\")\n",
    "    response = model.invoke(messages)\n",
    "    logging.info(f\"Model response: {response}\")\n",
    "    if not response.content.strip():\n",
    "        response.content = messages[-1].content\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_tool(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    logging.info(f\"Invoking tool with message: {last_message}\")\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        )\n",
    "    )\n",
    "    logging.info(f\"Tool action: {action}\")\n",
    "    response = tool_executor.invoke(action)\n",
    "    logging.info(f\"Tool response: {response}\")\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "async def fetch_and_generate_answer(question: str):\n",
    "    # Mock implementation of RAG functions\n",
    "    retrieved_docs = await fetch_similar_docs(question)  # Replace with actual function\n",
    "    if not retrieved_docs or all(doc.page_content.strip() == \"\" for doc in retrieved_docs):\n",
    "        return None\n",
    "    result = await generate_answer(question, retrieved_docs)  # Replace with actual function\n",
    "    if result == \"I don't know.\":\n",
    "        return None\n",
    "    return result\n",
    "\n",
    "async def call_rag(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    question = last_message.content\n",
    "    logging.info(f\"Calling RAG with question: {question}\")\n",
    "    result = await fetch_and_generate_answer(question)\n",
    "    if result is None:\n",
    "        logging.info(f\"Performing DuckDuckGo search for question: {question}\")\n",
    "        action = ToolInvocation(tool=\"DuckDuckGoSearchRun\", tool_input={\"query\": question})\n",
    "        response = tool_executor.invoke(action)\n",
    "        function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "        return {\"messages\": [function_message]}\n",
    "    elif result == \"I don't know.\":\n",
    "        return {\"messages\": [HumanMessage(content=result, type='human')], \"end\": END}\n",
    "    else:\n",
    "        logging.info(f\"RAG result: {result}\")\n",
    "        content = result['response'].content\n",
    "        return {\"messages\": [HumanMessage(content=content, type='human')]}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "workflow.add_node(\"rag\", call_rag)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "def should_use_tool_or_rag(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    logging.info(f\"Last message: {last_message.content}\")\n",
    "    if isinstance(last_message, AIMessage) and last_message.content.lower() == \"i don't know.\":\n",
    "        logging.info(\"Returning 'tool'\")\n",
    "        return \"tool\"\n",
    "    if isinstance(last_message, FunctionMessage) and last_message.name == \"DuckDuckGoSearchRun\":\n",
    "        logging.info(\"Returning 'rag'\")\n",
    "        return \"rag\"\n",
    "    return \"rag\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_use_tool_or_rag,\n",
    "    {\n",
    "        \"tool\": \"action\",\n",
    "        \"rag\": \"rag\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "workflow.add_edge(\"rag\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_query(question):\n",
    "    logging.info(f\"Question: {question}\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=question, type='human')]}\n",
    "    while True:\n",
    "        response = await app.ainvoke(inputs)\n",
    "        if 'messages' not in response or not response['messages']:\n",
    "            logging.error(\"No valid response received\")\n",
    "            break  # Break the loop if there is no valid response\n",
    "        result_message = response['messages'][0]\n",
    "        result_content = result_message.content\n",
    "        if isinstance(result_content, str) and result_content.strip() and result_content != \"I don't know.\":\n",
    "            return {\"messages\": [HumanMessage(content=result_content, type='human')]}\n",
    "        elif 'end' in response and response['end'] == END:\n",
    "            logging.info(\"Reached END state\")\n",
    "            return {\"messages\": [HumanMessage(content=result_content, type='human')]}\n",
    "        elif isinstance(result_message, AIMessage) and result_content == \"I don't know.\":\n",
    "            logging.info(f\"Performing DuckDuckGo search for question: {question}\")\n",
    "            action = ToolInvocation(tool=\"DuckDuckGoSearchRun\", tool_input={\"query\": question})\n",
    "            response = tool_executor.invoke(action)\n",
    "            function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "            return {\"messages\": [function_message]}\n",
    "        else:\n",
    "            logging.info(f\"Unexpected result type or no valid response: {type(result_content)}\")\n",
    "            break  # Break the loop once a response is generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Question: What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?\n",
      "INFO:root:Calling model with messages: [HumanMessage(content='What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Model response: content='' additional_kwargs={'function_call': {'arguments': '{\"query\":\"Tenacious Talent - GenAI UpSkilling GEN-AI Challenge\"}', 'name': 'duckduckgo_search'}} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 92, 'total_tokens': 121}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None} id='run-cb9c67ad-f912-45ce-9c0a-109a62e8b11e-0' usage_metadata={'input_tokens': 92, 'output_tokens': 29, 'total_tokens': 121}\n",
      "INFO:root:Last message: What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?\n",
      "INFO:root:Calling RAG with question: What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:RAG result: {'response': AIMessage(content='Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition or challenge organized by a company or organization called Tenacious Talent in collaboration with GenAI focused on upskilling individuals in artificial intelligence (AI) through various challenges and tasks. Participants may have to showcase their AI skills and compete for prizes or recognition in the field of AI.', response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 82, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-44cd8714-872b-44a4-98be-47f31f6c6d30-0', usage_metadata={'input_tokens': 82, 'output_tokens': 71, 'total_tokens': 153}), 'context': 'What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?', 'question': 'What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?'}\n",
      "INFO:root:Calling model with messages: [HumanMessage(content='What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?'), AIMessage(content='What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Tenacious Talent - GenAI UpSkilling GEN-AI Challenge\"}', 'name': 'duckduckgo_search'}}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 92, 'total_tokens': 121}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-cb9c67ad-f912-45ce-9c0a-109a62e8b11e-0', usage_metadata={'input_tokens': 92, 'output_tokens': 29, 'total_tokens': 121}), HumanMessage(content='Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition or challenge organized by a company or organization called Tenacious Talent in collaboration with GenAI focused on upskilling individuals in artificial intelligence (AI) through various challenges and tasks. Participants may have to showcase their AI skills and compete for prizes or recognition in the field of AI.')]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Model response: content='Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition organized by Tenacious Talent in collaboration with GenAI, aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks. Participants can showcase their AI skills and compete for prizes or recognition in the field of AI.' response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 219, 'total_tokens': 282}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-cda897ff-1cb2-43c8-acb1-04c90f0b169f-0' usage_metadata={'input_tokens': 219, 'output_tokens': 63, 'total_tokens': 282}\n",
      "INFO:root:Last message: Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition organized by Tenacious Talent in collaboration with GenAI, aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks. Participants can showcase their AI skills and compete for prizes or recognition in the field of AI.\n",
      "INFO:root:Calling RAG with question: Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition organized by Tenacious Talent in collaboration with GenAI, aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks. Participants can showcase their AI skills and compete for prizes or recognition in the field of AI.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:RAG result: {'response': AIMessage(content='The competition is aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks, allowing them to showcase their skills and potentially win prizes or recognition in the field of AI.', response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 174, 'total_tokens': 212}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c752f937-fc33-42ae-8bae-8f2d910cf20c-0', usage_metadata={'input_tokens': 174, 'output_tokens': 38, 'total_tokens': 212}), 'context': 'Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition organized by Tenacious Talent in collaboration with GenAI, aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks. Participants can showcase their AI skills and compete for prizes or recognition in the field of AI.', 'question': 'Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition organized by Tenacious Talent in collaboration with GenAI, aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks. Participants can showcase their AI skills and compete for prizes or recognition in the field of AI.'}\n",
      "INFO:root:Calling model with messages: [HumanMessage(content='What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?'), AIMessage(content='What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Tenacious Talent - GenAI UpSkilling GEN-AI Challenge\"}', 'name': 'duckduckgo_search'}}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 92, 'total_tokens': 121}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-cb9c67ad-f912-45ce-9c0a-109a62e8b11e-0', usage_metadata={'input_tokens': 92, 'output_tokens': 29, 'total_tokens': 121}), HumanMessage(content='Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition or challenge organized by a company or organization called Tenacious Talent in collaboration with GenAI focused on upskilling individuals in artificial intelligence (AI) through various challenges and tasks. Participants may have to showcase their AI skills and compete for prizes or recognition in the field of AI.'), AIMessage(content='Tenacious Talent - GenAI UpSkilling GEN-AI Challenge is a competition organized by Tenacious Talent in collaboration with GenAI, aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks. Participants can showcase their AI skills and compete for prizes or recognition in the field of AI.', response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 219, 'total_tokens': 282}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cda897ff-1cb2-43c8-acb1-04c90f0b169f-0', usage_metadata={'input_tokens': 219, 'output_tokens': 63, 'total_tokens': 282}), HumanMessage(content='The competition is aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks, allowing them to showcase their skills and potentially win prizes or recognition in the field of AI.')]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Model response: content='The competition is aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks, allowing them to showcase their skills and potentially win prizes or recognition in the field of AI.' response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 327, 'total_tokens': 366}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9b398de0-f94d-4731-bad6-9f986704a558-0' usage_metadata={'input_tokens': 327, 'output_tokens': 39, 'total_tokens': 366}\n",
      "INFO:root:Last message: The competition is aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks, allowing them to showcase their skills and potentially win prizes or recognition in the field of AI.\n",
      "INFO:root:Calling RAG with question: The competition is aimed at upskilling individuals in artificial intelligence (AI) through challenges and tasks, allowing them to showcase their skills and potentially win prizes or recognition in the field of AI.\n",
      "/home/mubarek/anaconda3/envs/team-mate/lib/python3.11/asyncio/selector_events.py:868: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=73 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/mubarek/anaconda3/envs/team-mate/lib/python3.11/asyncio/selector_events.py:868: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=77 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m answer1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m ask_query(question1)\n\u001b[1;32m      3\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m, in \u001b[0;36mask_query\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mquestion, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m)]}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m app\u001b[38;5;241m.\u001b[39mainvoke(inputs)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      7\u001b[0m         logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid response received\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1440\u001b[0m, in \u001b[0;36mPregel.ainvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1440\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1442\u001b[0m     config,\n\u001b[1;32m   1443\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1444\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1445\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[1;32m   1446\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1447\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1448\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1450\u001b[0m ):\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1452\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1347\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;66;03m# wait for all background tasks to finish\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mbg)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langgraph/pregel/retry.py:114\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, task\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/runnables/base.py:2436\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2436\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   2437\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2438\u001b[0m             \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m             patch_config(\n\u001b[1;32m   2440\u001b[0m                 config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2441\u001b[0m             ),\n\u001b[1;32m   2442\u001b[0m         )\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langgraph/utils.py:117\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[36], line 61\u001b[0m, in \u001b[0;36mcall_rag\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     59\u001b[0m question \u001b[38;5;241m=\u001b[39m last_message\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     60\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling RAG with question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch_and_generate_answer(question)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming DuckDuckGo search for question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 52\u001b[0m, in \u001b[0;36mfetch_and_generate_answer\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m retrieved_docs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(doc\u001b[38;5;241m.\u001b[39mpage_content\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m retrieved_docs):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m generate_answer(question, retrieved_docs)  \u001b[38;5;66;03m# Replace with actual function\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/tenacity/_asyncio.py:142\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\n\u001b[1;32m    139\u001b[0m     fn, functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__kwdefaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masync_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/tenacity/_asyncio.py:58\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/tenacity/_asyncio.py:110\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    108\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 110\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/tenacity/_asyncio.py:78\u001b[0m, in \u001b[0;36mAsyncRetrying._wrap_action_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/tenacity/__init__.py:390\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/tenacity/_asyncio.py:61\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 34\u001b[0m, in \u001b[0;36mgenerate_answer\u001b[0;34m(question, retrieved_docs)\u001b[0m\n\u001b[1;32m     29\u001b[0m input_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\n\u001b[1;32m     32\u001b[0m }\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m retrieval_augmented_generation_chain\u001b[38;5;241m.\u001b[39mainvoke(input_data)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/runnables/base.py:2436\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2436\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   2437\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2438\u001b[0m             \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m             patch_config(\n\u001b[1;32m   2440\u001b[0m                 config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2441\u001b[0m             ),\n\u001b[1;32m   2442\u001b[0m         )\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/runnables/base.py:3072\u001b[0m, in \u001b[0;36mRunnableParallel.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3070\u001b[0m     \u001b[38;5;66;03m# copy to avoid issues from the caller mutating the steps during invoke()\u001b[39;00m\n\u001b[1;32m   3071\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps__)\n\u001b[0;32m-> 3072\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m   3073\u001b[0m         \u001b[38;5;241m*\u001b[39m(\n\u001b[1;32m   3074\u001b[0m             step\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   3075\u001b[0m                 \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3076\u001b[0m                 \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[1;32m   3077\u001b[0m                 patch_config(\n\u001b[1;32m   3078\u001b[0m                     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3079\u001b[0m                 ),\n\u001b[1;32m   3080\u001b[0m             )\n\u001b[1;32m   3081\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3082\u001b[0m         )\n\u001b[1;32m   3083\u001b[0m     )\n\u001b[1;32m   3084\u001b[0m     output \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, results)}\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/runnables/base.py:2436\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2436\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   2437\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2438\u001b[0m             \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m             patch_config(\n\u001b[1;32m   2440\u001b[0m                 config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2441\u001b[0m             ),\n\u001b[1;32m   2442\u001b[0m         )\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:191\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    190\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 191\u001b[0m     llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    192\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    193\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    194\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    195\u001b[0m         tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    196\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    197\u001b[0m         run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    198\u001b[0m         run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ChatGeneration, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:609\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    603\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    607\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    608\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[1;32m    610\u001b[0m         prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    611\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:535\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m AsyncCallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m    516\u001b[0m     callbacks,\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    523\u001b[0m )\n\u001b[1;32m    525\u001b[0m run_managers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mon_chat_model_start(\n\u001b[1;32m    526\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    527\u001b[0m     messages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m    533\u001b[0m )\n\u001b[0;32m--> 535\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate_with_cache(\n\u001b[1;32m    538\u001b[0m             m,\n\u001b[1;32m    539\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    540\u001b[0m             run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    542\u001b[0m         )\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages)\n\u001b[1;32m    544\u001b[0m     ],\n\u001b[1;32m    545\u001b[0m     return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    546\u001b[0m )\n\u001b[1;32m    547\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:754\u001b[0m, in \u001b[0;36mBaseChatModel._agenerate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 754\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[1;32m    755\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    756\u001b[0m         )\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:657\u001b[0m, in \u001b[0;36mBaseChatOpenAI._agenerate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    656\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 657\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/openai/resources/chat/completions.py:1181\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1183\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   1184\u001b[0m             {\n\u001b[1;32m   1185\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1186\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1187\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1188\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1189\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1190\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1191\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1192\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1193\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1194\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1195\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1196\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1197\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1198\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1199\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1200\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1201\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1202\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1203\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1204\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1205\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1206\u001b[0m             },\n\u001b[1;32m   1207\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m   1208\u001b[0m         ),\n\u001b[1;32m   1209\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1210\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1211\u001b[0m         ),\n\u001b[1;32m   1212\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1213\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1214\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   1215\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/openai/_base_client.py:1790\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1778\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1785\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1786\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1787\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1788\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1789\u001b[0m     )\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/openai/_base_client.py:1493\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1486\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m-> 1493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1494\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1495\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1496\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1497\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1498\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m   1499\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/openai/_base_client.py:1522\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1522\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m   1523\u001b[0m         request,\n\u001b[1;32m   1524\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1526\u001b[0m     )\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1528\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpx/_client.py:1661\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m   1653\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m   1657\u001b[0m )\n\u001b[1;32m   1659\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m-> 1661\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m   1662\u001b[0m     request,\n\u001b[1;32m   1663\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1664\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1665\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   1666\u001b[0m )\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpx/_client.py:1689\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1686\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auth_flow\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m   1690\u001b[0m         request,\n\u001b[1;32m   1691\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1692\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m   1693\u001b[0m     )\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1695\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpx/_client.py:1726\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1724\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[0;32m-> 1726\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpx/_client.py:1763\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1759\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1760\u001b[0m     )\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1763\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n\u001b[1;32m   1766\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpx/_transports/default.py:373\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    360\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    361\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    362\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    371\u001b[0m )\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 373\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    378\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    379\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    380\u001b[0m     stream\u001b[38;5;241m=\u001b[39mAsyncResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    381\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    382\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:216\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncIterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:196\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_async/connection.py:101\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_async/http11.py:143\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_async/http11.py:95\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msend_request_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WriteError:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# If we get a write error while we're writing the request,\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# then we supress this error and move on to attempting to\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# read the response. Servers can sometimes close the request\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# pre-emptively and then respond with a well formed HTTP\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# error response.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_async/http11.py:166\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._send_request_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m request\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m    165\u001b[0m     event \u001b[38;5;241m=\u001b[39m h11\u001b[38;5;241m.\u001b[39mData(data\u001b[38;5;241m=\u001b[39mchunk)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_event(event, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_event(h11\u001b[38;5;241m.\u001b[39mEndOfMessage(), timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_async/http11.py:175\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._send_event\u001b[0;34m(self, event, timeout)\u001b[0m\n\u001b[1;32m    173\u001b[0m bytes_to_send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39msend(event)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bytes_to_send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mwrite(bytes_to_send, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/httpcore/_backends/anyio.py:52\u001b[0m, in \u001b[0;36mAnyIOStream.write\u001b[0;34m(self, buffer, timeout)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mfail_after(timeout):\n\u001b[0;32m---> 52\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39msend(item\u001b[38;5;241m=\u001b[39mbuffer)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/anyio/streams/tls.py:212\u001b[0m, in \u001b[0;36mTLSStream.send\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_sslobject_method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_object\u001b[38;5;241m.\u001b[39mwrite, item)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/anyio/streams/tls.py:178\u001b[0m, in \u001b[0;36mTLSStream._call_sslobject_method\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# Flush any pending writes first\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_bio\u001b[38;5;241m.\u001b[39mpending:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_stream\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_bio\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:1171\u001b[0m, in \u001b[0;36mSocketStream.send\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_guard:\n\u001b[0;32m-> 1171\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m AsyncIOBackend\u001b[38;5;241m.\u001b[39mcheckpoint()\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m   1174\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ClosedResourceError\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:2050\u001b[0m, in \u001b[0;36mAsyncIOBackend.checkpoint\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheckpoint\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2050\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/asyncio/tasks.py:640\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Coroutine that completes after a given time (in seconds).\"\"\"\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delay \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m __sleep0()\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    643\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n",
      "File \u001b[0;32m~/anaconda3/envs/team-mate/lib/python3.11/asyncio/tasks.py:634\u001b[0m, in \u001b[0;36m__sleep0\u001b[0;34m()\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;129m@types\u001b[39m\u001b[38;5;241m.\u001b[39mcoroutine\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sleep0\u001b[39m():\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Skip one event loop run cycle.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    This is a private helper for 'asyncio.sleep()', used\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    instead of creating a Future object.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question1 = \"What is Tenacious Talent - GenAI UpSkilling GEN-AI Challenge?\"\n",
    "answer1 = await ask_query(question1)\n",
    "logging.info(f\"Answer: {answer1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"Can you tell me about Langsmith?\"\n",
    "answer2 = await ask_query(question2)\n",
    "logging.info(f\"Answer: {answer2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "\n",
    "# Create an instance of the tool\n",
    "tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Use the tool to perform a search\n",
    "result = tool._run(\"can you tell me about langsmith?\")\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team-mate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
